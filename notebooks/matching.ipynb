{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity of left and right profiles of sea turtles\n",
    "\n",
    "This notebook analyzes the differences between left and right profiles for sea turtles. We analyzed three different species (loggerheads, grees and hawksbills) with the uniform conclusion that there is a significant similarity between opposite profile in all three species. The main conclusion of this observation is that biologists should used both profiles for identifying individuals and not only the same profile as the current practise goes.\n",
    "\n",
    "We first load the required packages and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from wildlife_datasets import datasets\n",
    "from sides_matching import Prediction, Data_MegaDescriptor, Data_SIFT, Data_TORSOOI\n",
    "from sides_matching import get_dataset, get_transform, get_box_plot_data\n",
    "from sift_matching import Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already assume that the data were downloaded and the features extracted. If this is not the case, please run first [this notebook](compute_features.ipynb). The next codes specifies the folders whether data are stored and where results will be saved. The variable 'data' states that we will run experiments on datasets ZakynthosTurtles, AmvrakikosTurtles and ReunionTurtles, while the last dataset will be analyzed separately for green and hawksbill turtles. Concerning methods, we will use MegaDescriptor, SIFT and TORSOOI codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_datasets = '../data'\n",
    "root_features = '../features'\n",
    "root_figures = '../figures'\n",
    "root_images = '../images'\n",
    "data = [\n",
    "    ('Zakynthos-Loggerheads MegaDescriptor', datasets.ZakynthosTurtles, 'MegaDescriptor', {}),\n",
    "    ('Amvrakikos-Loggerheads MegaDescriptor', datasets.AmvrakikosTurtles, 'MegaDescriptor', {}),\n",
    "    ('Reunion-Greens MegaDescriptor', datasets.ReunionTurtles, 'MegaDescriptor', {'species': 'Green'}),\n",
    "    ('Reunion-Hawksbills MegaDescriptor', datasets.ReunionTurtles, 'MegaDescriptor', {'species': 'Hawksbill'}),\n",
    "    ('Zakynthos-Loggerheads SIFT', datasets.ZakynthosTurtles, 'SIFT', {}),\n",
    "    ('Amvrakikos-Loggerheads SIFT', datasets.AmvrakikosTurtles, 'SIFT', {}),\n",
    "    ('Reunion-Greens SIFT', datasets.ReunionTurtles, 'SIFT', {'species': 'Green'}),\n",
    "    ('Reunion-Hawksbills SIFT', datasets.ReunionTurtles, 'SIFT', {'species': 'Hawksbill'}),\n",
    "    ('Reunion-Greens TORSOOI', datasets.ReunionTurtles, 'TORSOOI', {'species': 'Green'}),\n",
    "    ('Reunion-Hawksbills TORSOOI', datasets.ReunionTurtles, 'TORSOOI', {'species': 'Hawksbill'}),\n",
    "]\n",
    "\n",
    "for root in [root_features, root_figures, root_images]:\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "names = [x[0] for x in data]\n",
    "names_methods = [name.split(' ')[-1] for name in names]\n",
    "names_datasets = [name.split(' ')[0] for name in names]\n",
    "data_index = pd.MultiIndex.from_arrays([names_methods, names_datasets], names=['Method', 'Dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code computes the scores and predictions for the query images. The scores are computed for pairs are of images. The computations of scores is as follows:\n",
    "\n",
    "- MegaDescriptor: the cosine similarity between the extracted features.\n",
    "- SIFT: the negative distance between 15 closest descriptors.\n",
    "- TORSOOI: the number of matching number of edges from TORSOOI codes.\n",
    "\n",
    "The predictions are computed as the images with the highest similarity to the query image. We return not only the usual top-1 prediction but a sorted array of all scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {x: {} for x in [True, False]}\n",
    "img_size_SIFT = 90\n",
    "for grayscale in [True, False]:\n",
    "    for name, dataset_class, metric, pars_split in data:\n",
    "        # Load dataset\n",
    "        root_dataset = os.path.join(root_datasets, dataset_class.__name__)\n",
    "        df = get_dataset(dataset_class, root_dataset).df\n",
    "        # Get split into database (empty) and query\n",
    "        idx_database = []    \n",
    "        idx_ignore = []    \n",
    "        for key, value in pars_split.items():\n",
    "            idx_ignore = idx_ignore + list(np.where(df[key] != value)[0])    \n",
    "        idx_query = np.setdiff1d(np.arange(len(df)), idx_ignore)\n",
    "        # Define score_computer for each method\n",
    "        if metric == 'MegaDescriptor':\n",
    "            path_features_query = os.path.join(root_features, f'features_{dataset_class.__name__}_flip={False}_grayscale={grayscale}.npy')\n",
    "            path_features_database = os.path.join(root_features, f'features_{dataset_class.__name__}_flip={False}_grayscale={grayscale}.npy')\n",
    "            score_computer = Data_MegaDescriptor(path_features_query, path_features_database)\n",
    "        elif metric == 'SIFT':\n",
    "            transform = get_transform(flip=False, grayscale=grayscale, img_size=img_size_SIFT, normalize=False)\n",
    "            if transform is not None:\n",
    "                transform = T.Compose([T.Lambda(lambda x: Image.fromarray(x)), *transform.transforms, T.Lambda(lambda x: np.array(x))])\n",
    "            img_load = 'bbox' if 'bbox' in df.columns else 'full'\n",
    "            image_loader = Loader(img_load=img_load, img_size=None, transform=transform, transform_name=f'{grayscale}+{img_size_SIFT}')\n",
    "            path_features = os.path.join(root_features, f'features_{dataset_class.__name__}_flip={False}_grayscale={grayscale}_SIFT')        \n",
    "            score_computer = Data_SIFT(root_dataset, path_features, df, image_loader=image_loader)        \n",
    "        elif metric == 'TORSOOI':\n",
    "            score_computer = Data_TORSOOI(df)\n",
    "        else:\n",
    "            raise Exception('Metric now known')\n",
    "        # Compute scores and predictions based on closest scores\n",
    "        idx_true, idx_pred, scores = score_computer.compute_scores(idx_query)\n",
    "        prediction = Prediction(df, idx_true, idx_pred, scores, df['identity'].iloc[idx_query].nunique())\n",
    "        predictions[grayscale][name] = prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the predictions, the accuracy is computed. The top-1 accuracy is the standard accuracy, which computes the ratio of correct matches of the closests predictions. Top-k accuracy is deemed a success when at least one of the top-k sorted predictions is a success (the prediction is the same as the true identity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = ['full', 'same year', 'same orientation', 'different both', 'different year']\n",
    "mods_text = ['all images', 'A: diff side, same year', 'B: same side, diff year', 'C: diff side, diff year', 'B+C: any side, diff year']\n",
    "for grayscale in [True, False]:\n",
    "    for _, prediction in predictions[grayscale].items():\n",
    "        prediction.compute_accuracy(mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the accuracy for all methods and all datasets. The images are saved into the `root_figures` folder. As an example, one figure is plotted in this notebook as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grayscale in [True, False]:\n",
    "    for i_name, name in enumerate(names):\n",
    "        prediction = predictions[grayscale][name]\n",
    "        xs = range(1, 1+prediction.n_individuals)\n",
    "        df_save = pd.DataFrame()\n",
    "        df_save['k'] = xs\n",
    "        plt.figure()\n",
    "        for mod in mods:\n",
    "            ys = [prediction.accuracy[mod][f'top {i}'] for i in xs]\n",
    "            df_save[mod] = ys\n",
    "            plt.plot(xs, ys)\n",
    "        df_save.to_csv(os.path.join(root_figures, f'accuracy_{name}_{grayscale}.csv'), index=False)\n",
    "        plt.axhline(1, color='black', linestyle='dotted')\n",
    "        plt.xlim([1, 10])\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('top k accuracy')\n",
    "        plt.legend(mods_text)\n",
    "        plt.title(f'{name}, grayscale = {grayscale}')\n",
    "        plt.savefig(os.path.join(root_figures, f'accuracy_{name}_{grayscale}.png'), bbox_inches='tight')\n",
    "        if i_name > 0 or grayscale:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous figures may be visualized as a table. We show the top-5 accuracy for all methods and all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'top 5'\n",
    "accuracy_top = {x: {mod: [] for mod in mods} for x in [True, False]}    \n",
    "for grayscale in [True, False]:\n",
    "    for name in names:\n",
    "        prediction = predictions[grayscale][name]\n",
    "        for mod in mods:\n",
    "            accuracy_top[grayscale][mod].append(prediction.accuracy[mod][metric])\n",
    "    df_save = pd.DataFrame(accuracy_top[grayscale], index=data_index)\n",
    "    df_latex = df_save.to_latex(float_format='%.3f')\n",
    "    print(f'Grayscale = {grayscale}')\n",
    "    display(df_save)\n",
    "    with open(os.path.join(root_figures, f'accuracy_{metric}_{grayscale}.txt'), 'w') as file:\n",
    "        file.write(df_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code graphically shows the boxplot of all similarities for the various settings mentioned in the paper. As in the previous case, all figures are saved into `root_figures` and only one is plotted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = {x: {name: {} for name in names} for x in [True, False]}\n",
    "boxplot_data = {x: {name: {} for name in names} for x in [True, False]}\n",
    "for grayscale in [True, False]:\n",
    "    for i_name, name in enumerate(names):\n",
    "        similarity_split = predictions[grayscale][name].split_scores()\n",
    "        similarity_boxplot = [\n",
    "            # identity, orientation, year\n",
    "            similarity_split[True][False][True],\n",
    "            similarity_split[True][True][False],\n",
    "            similarity_split[True][False][False],\n",
    "            similarity_split[False][True][True] + similarity_split[False][True][False],\n",
    "            similarity_split[False][False][True] + similarity_split[False][False][False],\n",
    "        ]\n",
    "        names_boxplot = [\n",
    "            '(A): same ind, diff side, same year',\n",
    "            '(B): same ind, same side, diff year',\n",
    "            '(C): same ind, diff side, diff year',\n",
    "            '(D): diff ind, same side',\n",
    "            '(E): diff ind, diff side',\n",
    "        ]\n",
    "\n",
    "        for i in range(len(similarity_boxplot)):\n",
    "            similarity_boxplot[i] = np.array(similarity_boxplot[i])[np.isfinite(similarity_boxplot[i])]\n",
    "        \n",
    "        for i, j, alt, comparison in zip([0,0,1,2,3], [1,2,2,3,4], ['two-sided', 'greater', 'greater', 'greater', 'two-sided'], ['A!=B', 'A>C', 'B>C', 'C>D', 'D!=E']):\n",
    "            _, p_value = ttest_ind(similarity_boxplot[i], similarity_boxplot[j], alternative=alt)\n",
    "            p_values[grayscale][name][comparison] = np.round(p_value, 3)\n",
    "\n",
    "        plt.figure()\n",
    "        fig = plt.boxplot(similarity_boxplot)\n",
    "        plt.xticks(range(1, len(names_boxplot)+1), names_boxplot, rotation=25)\n",
    "        plt.ylabel('similarity')\n",
    "        plt.title(name)\n",
    "        plt.savefig(os.path.join(root_figures, f'similarity_{name}_{grayscale}.png'), bbox_inches='tight')\n",
    "        if i_name > 0 or grayscale:\n",
    "            plt.close()\n",
    "        boxplot_data[grayscale][name] = get_box_plot_data(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the p-values that the individual settings have the same similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grayscale in [True, False]:\n",
    "    df_save = pd.DataFrame(p_values[grayscale]).T.set_index(data_index)\n",
    "    df_latex = df_save.to_latex(float_format='%.3f')\n",
    "    print(f'Grayscale = {grayscale}')\n",
    "    display(df_save)\n",
    "    with open(os.path.join(root_figures, f'pvalues_{metric}_{grayscale}.txt'), 'w') as file:\n",
    "        file.write(df_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [\n",
    "    'col1, ylabel={Zakynthos-Loggerheads}, title={MegaDescriptor}, xticklabels={}',\n",
    "    'col2, ylabel={}, title={SIFT}, xticklabels={}, yticklabels={}',\n",
    "    'col3, group/empty plot, title={TORSOI}',\n",
    "    'col1, ylabel={Amvrakikos-Loggerheads}, title={}, xticklabels={}',\n",
    "    'col2, ylabel={}, title={}, xticklabels={}, yticklabels={}',\n",
    "    'col3, group/empty plot, title={}',\n",
    "    'col1, ylabel={Reunion-Greens}, title={}, xticklabels={}',\n",
    "    'col2, ylabel={}, title={}, xticklabels={}, yticklabels={}',\n",
    "    'col3, ylabel={}, title={}, xticklabels={}, yticklabels={}',\n",
    "    'col1, xlabel={similarity}, ylabel={Reunion-Hawksbills}, title={}',\n",
    "    'col2, xlabel={similarity}, ylabel={}, title={}, yticklabels={}',\n",
    "    'col3, xlabel={similarity}, ylabel={}, title={}, yticklabels={}',\n",
    "]\n",
    "names_order = [\n",
    "    'Zakynthos-Loggerheads MegaDescriptor',\n",
    "    'Zakynthos-Loggerheads SIFT',\n",
    "    '',\n",
    "    'Amvrakikos-Loggerheads MegaDescriptor',\n",
    "    'Amvrakikos-Loggerheads SIFT',\n",
    "    '',\n",
    "    'Reunion-Greens MegaDescriptor',\n",
    "    'Reunion-Greens SIFT',\n",
    "    'Reunion-Greens TORSOOI',\n",
    "    'Reunion-Hawksbills MegaDescriptor',\n",
    "    'Reunion-Hawksbills SIFT',\n",
    "    'Reunion-Hawksbills TORSOOI'\n",
    "]\n",
    "\n",
    "for grayscale in [True, False]:\n",
    "    for name, flag in zip(names_order, flags):\n",
    "        print(f'\\\\nextgroupplot[{flag}]')\n",
    "        if name != '':\n",
    "            bp_data = boxplot_data[grayscale][name]\n",
    "            for _, row in bp_data[::-1].iterrows():\n",
    "                l_w = np.round(row[\"lower_whisker\"],2)\n",
    "                l_q = np.round(row[\"lower_quartile\"],2)\n",
    "                median = np.round(row[\"median\"],2)\n",
    "                u_q = np.round(row[\"upper_quartile\"],2)\n",
    "                u_w = np.round(row[\"upper_whisker\"],2)\n",
    "                print(f'\\\\addboxplot{{bp}}{{{median}}}{{{u_q}}}{{{l_q}}}{{{u_w}}}{{{l_w}}};')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grayscale in [True, False]:\n",
    "    for name, dataset_class, _, _ in data[:4]:\n",
    "        similarity_split = predictions[grayscale][name].split_scores(save_idx=True)\n",
    "        \n",
    "        similarity_boxplot = [\n",
    "            # identity, orientation, year\n",
    "            similarity_split[True][False][True],\n",
    "            similarity_split[True][False][False],\n",
    "        ]\n",
    "        names_boxplot = [\n",
    "            '(A)',\n",
    "            '(C)',\n",
    "        ]\n",
    "\n",
    "        root_dataset = os.path.join(root_datasets, dataset_class.__name__)\n",
    "        prediction = predictions[grayscale][name]\n",
    "        transform = get_transform(flip=False, grayscale=grayscale, normalize=False)\n",
    "        dataset = dataset_class(root_dataset, img_load='auto', transform=transform)\n",
    "        \n",
    "        for i in range(len(similarity_boxplot)):\n",
    "            for score_selection in ['top', 'bottom']:\n",
    "                sim = similarity_boxplot[i]\n",
    "                sim = sorted(sim, key=lambda x: (x[0]))\n",
    "                if score_selection == 'top':\n",
    "                    sim = sim[::-1]\n",
    "                idx1 = [sim[0][1], sim[0][2]] if prediction.orientation[sim[0][1]] == 'right' else [sim[0][2], sim[0][1]]\n",
    "                idx2 = [sim[2][1], sim[2][2]] if prediction.orientation[sim[2][1]] == 'right' else [sim[2][2], sim[2][1]]\n",
    "                idx = idx1 + idx2\n",
    "\n",
    "                header_cols = [f'{names_boxplot[i]}, {score_selection}', '']\n",
    "                for j1, j2 in enumerate(idx):\n",
    "                    img = dataset[j2]\n",
    "                    new_height = int(200)\n",
    "                    new_width  = int(new_height * img.size[0] / img.size[1])\n",
    "                    img = img.resize((new_width, new_height))\n",
    "                    img.save(os.path.join(root_images, f'sim_{name}_{score_selection}_{grayscale}_{i}_{j1}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grayscale in [True, False]:\n",
    "    transform = get_transform(flip=False, grayscale=grayscale, normalize=False)\n",
    "    for name, dataset_class, _, _ in data[:4]:\n",
    "        root_dataset = os.path.join(root_datasets, dataset_class.__name__)\n",
    "        prediction = predictions[grayscale][name]\n",
    "        dataset = dataset_class(root_dataset, img_load='auto', transform=transform)\n",
    "        if 'year' not in dataset.df.columns:\n",
    "            dataset.df['year'] = pd.to_datetime(dataset.df['date']).apply(lambda x: x.year)\n",
    "\n",
    "        for i, identity in enumerate(dataset.df.identity[prediction.true].unique()[:1]):\n",
    "            idx = list(np.where(dataset.df['identity'] == identity)[0])\n",
    "            idx = dataset.df.iloc[idx].sort_values(['year', 'orientation'])[::-1].index\n",
    "            idx = dataset.df.index.get_indexer(idx)\n",
    "            dataset.plot_grid(idx=idx, n_rows=1, n_cols=4, transform=transform);            \n",
    "            plt.savefig(os.path.join(root_figures, f'grid_{name}_{grayscale}_{i}.png'), bbox_inches='tight')\n",
    "            plt.close()\n",
    "            for j_save, j in enumerate(idx):\n",
    "                img = dataset[j]\n",
    "                new_height = int(200)\n",
    "                new_width  = int(new_height * img.size[0] / img.size[1])\n",
    "                img = img.resize((new_width, new_height))\n",
    "                img.save(os.path.join(root_images, f'img_{name}_{grayscale}_{i}_{j_save}.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
